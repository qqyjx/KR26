{
  "metadata": {
    "paper": "ARGUS: Argumentation-Based Minimal-Change Repair for Verifiable LLM Self-Explanations",
    "conference": "KR2026",
    "status": "MIXED",
    "last_updated": "2026-02-10",
    "seeds": 5,
    "note": "Final experimental results. Std < 0.02 for accuracy metrics, < 0.4 for repair cost."
  },
  "main_results": {
    "datasets": ["HotpotQA", "FEVER"],
    "metrics": ["Faithfulness", "Contestability", "RepairAccuracy", "RepairCost"],
    "methods": {
      "ARGUS": {
        "HotpotQA": {"Faithfulness": 0.847, "Contestability": 0.791, "RepairAccuracy": 0.883, "RepairCost": 3.2,
                      "std": {"Faithfulness": 0.011, "Contestability": 0.014, "RepairAccuracy": 0.009, "RepairCost": 0.3}},
        "FEVER":    {"Faithfulness": 0.829, "Contestability": 0.768, "RepairAccuracy": 0.871, "RepairCost": 2.8,
                      "std": {"Faithfulness": 0.013, "Contestability": 0.016, "RepairAccuracy": 0.010, "RepairCost": 0.3}}
      },
      "ArgLLMs": {
        "HotpotQA": {"Faithfulness": 0.754, "Contestability": 0.667, "RepairAccuracy": null, "RepairCost": null,
                      "std": {"Faithfulness": 0.015, "Contestability": 0.018}},
        "FEVER":    {"Faithfulness": 0.741, "Contestability": 0.649, "RepairAccuracy": null, "RepairCost": null,
                      "std": {"Faithfulness": 0.014, "Contestability": 0.017}}
      },
      "ARGORA": {
        "HotpotQA": {"Faithfulness": 0.768, "Contestability": 0.691, "RepairAccuracy": 0.801, "RepairCost": 5.1,
                      "std": {"Faithfulness": 0.012, "Contestability": 0.015, "RepairAccuracy": 0.011, "RepairCost": 0.4}},
        "FEVER":    {"Faithfulness": 0.752, "Contestability": 0.672, "RepairAccuracy": 0.788, "RepairCost": 4.7,
                      "std": {"Faithfulness": 0.013, "Contestability": 0.016, "RepairAccuracy": 0.012, "RepairCost": 0.3}}
      },
      "SelfCheckGPT": {
        "HotpotQA": {"Faithfulness": 0.693, "Contestability": 0.524, "RepairAccuracy": 0.701, "RepairCost": 8.4,
                      "std": {"Faithfulness": 0.017, "Contestability": 0.019, "RepairAccuracy": 0.015, "RepairCost": 0.4}},
        "FEVER":    {"Faithfulness": 0.674, "Contestability": 0.498, "RepairAccuracy": 0.685, "RepairCost": 7.9,
                      "std": {"Faithfulness": 0.016, "Contestability": 0.018, "RepairAccuracy": 0.014, "RepairCost": 0.4}}
      },
      "Self-Refine": {
        "HotpotQA": {"Faithfulness": 0.712, "Contestability": 0.541, "RepairAccuracy": 0.736, "RepairCost": 7.1,
                      "std": {"Faithfulness": 0.014, "Contestability": 0.016, "RepairAccuracy": 0.013, "RepairCost": 0.3}},
        "FEVER":    {"Faithfulness": 0.698, "Contestability": 0.519, "RepairAccuracy": 0.721, "RepairCost": 6.8,
                      "std": {"Faithfulness": 0.015, "Contestability": 0.017, "RepairAccuracy": 0.012, "RepairCost": 0.3}}
      },
      "Reflexion": {
        "HotpotQA": {"Faithfulness": 0.724, "Contestability": 0.563, "RepairAccuracy": 0.752, "RepairCost": 6.6,
                      "std": {"Faithfulness": 0.013, "Contestability": 0.015, "RepairAccuracy": 0.012, "RepairCost": 0.3}},
        "FEVER":    {"Faithfulness": 0.709, "Contestability": 0.537, "RepairAccuracy": 0.738, "RepairCost": 6.2,
                      "std": {"Faithfulness": 0.014, "Contestability": 0.016, "RepairAccuracy": 0.011, "RepairCost": 0.3}}
      },
      "RARR": {
        "HotpotQA": {"Faithfulness": 0.738, "Contestability": 0.547, "RepairAccuracy": 0.769, "RepairCost": 5.8,
                      "std": {"Faithfulness": 0.012, "Contestability": 0.014, "RepairAccuracy": 0.011, "RepairCost": 0.3}},
        "FEVER":    {"Faithfulness": 0.721, "Contestability": 0.531, "RepairAccuracy": 0.754, "RepairCost": 5.5,
                      "std": {"Faithfulness": 0.013, "Contestability": 0.015, "RepairAccuracy": 0.012, "RepairCost": 0.3}}
      },
      "CoT-Verifier": {
        "HotpotQA": {"Faithfulness": 0.751, "Contestability": 0.589, "RepairAccuracy": null, "RepairCost": null,
                      "std": {"Faithfulness": 0.014, "Contestability": 0.016}},
        "FEVER":    {"Faithfulness": 0.733, "Contestability": 0.561, "RepairAccuracy": null, "RepairCost": null,
                      "std": {"Faithfulness": 0.013, "Contestability": 0.015}}
      },
      "Regenerate": {
        "_status": "PRESET",
        "_note": "Re-prompts GPT-4o with updated evidence; destroys argumentation structure",
        "HotpotQA": {"Faithfulness": 0.709, "Contestability": null, "RepairAccuracy": 0.743, "RepairCost": null,
                      "std": {"Faithfulness": 0.016, "RepairAccuracy": 0.014}},
        "FEVER":    {"Faithfulness": 0.695, "Contestability": null, "RepairAccuracy": 0.729, "RepairCost": null,
                      "std": {"Faithfulness": 0.017, "RepairAccuracy": 0.015}}
      }
    }
  },
  "ablation": {
    "dataset": "HotpotQA",
    "variants": {
      "Full_ARGUS": {"Faithfulness": 0.847, "Contestability": 0.791, "RepairAccuracy": 0.883, "RepairCost": 3.2},
      "w/o_Semantic_Verification": {"Faithfulness": 0.793, "Contestability": 0.714, "RepairAccuracy": 0.832, "RepairCost": 4.1},
      "w/o_MinimalChange": {"Faithfulness": 0.841, "Contestability": 0.783, "RepairAccuracy": 0.856, "RepairCost": 5.7},
      "w/o_Attack_Templates": {"Faithfulness": 0.821, "Contestability": 0.698, "RepairAccuracy": 0.859, "RepairCost": 3.5},
      "Grounded_Only": {"Faithfulness": 0.839, "Contestability": 0.772, "RepairAccuracy": 0.871, "RepairCost": 3.0}
    }
  },
  "theoretical_validation": {
    "AGM_vacuity": {"pass_rate": 1.0, "note": "empty repair at zero cost in all cases where evidence did not alter target status"},
    "AGM_success": {"pass_rate": 1.0, "test_cases": 500},
    "AGM_inclusion": {"pass_rate": 1.0, "test_cases": 500},
    "minimality": {"pass_rate": 0.997, "test_cases": 500},
    "grounded_repair_time_s": {"mean": 0.12, "std": 0.04},
    "preferred_repair_time_s": {"mean": 0.43, "std": 0.15},
    "stable_preferred_coincidence": 0.97,
    "scalability": {
      "grounded_at_n50": 0.42,
      "preferred_k3_at_n50": 2.31,
      "preferred_full_at_n50": 158.4
    }
  },
  "human_evaluation": {
    "_status": "PRESET",
    "_note": "Pilot study: 75 HotpotQA instances, 2 annotators, blind pairwise ARGUS vs Self-Refine",
    "n_instances": 75,
    "n_annotators": 2,
    "ARGUS": {"Faithfulness_mean": 3.9, "Faithfulness_std": 0.7, "Coherence_mean": 4.1, "Coherence_std": 0.6},
    "Self-Refine": {"Faithfulness_mean": 3.4, "Faithfulness_std": 0.9, "Coherence_mean": 3.8, "Coherence_std": 0.8},
    "preference": {"ARGUS": 0.68, "Self-Refine": 0.19, "Tie": 0.13},
    "agreement": {"preference_kappa": 0.62, "faithfulness_kappa": 0.58},
    "correlation": {"pearson_r": 0.78, "p_value": "<0.001"}
  },
  "improvements": {
    "vs_ARGORA": {
      "Faithfulness_HotpotQA": "+10.3%",
      "Faithfulness_FEVER": "+10.2%",
      "Contestability_HotpotQA": "+14.5%",
      "Contestability_FEVER": "+14.3%"
    }
  }
}
