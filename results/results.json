{
  "metadata": {
    "paper": "ARGUS: Argumentation-Based Minimal-Change Repair for Verifiable LLM Self-Explanations",
    "conference": "KR2026",
    "status": "PRESET",
    "last_updated": "2026-02-10",
    "note": "All values are reasonable presets. Replace with actual experimental results."
  },
  "main_results": {
    "datasets": ["HotpotQA", "FEVER"],
    "metrics": ["Faithfulness", "Contestability", "RepairAccuracy", "RepairCost"],
    "methods": {
      "ARGUS": {
        "HotpotQA": {"Faithfulness": 0.847, "Contestability": 0.791, "RepairAccuracy": 0.883, "RepairCost": 3.2},
        "FEVER": {"Faithfulness": 0.832, "Contestability": 0.768, "RepairAccuracy": 0.871, "RepairCost": 2.8}
      },
      "ArgLLMs": {
        "HotpotQA": {"Faithfulness": 0.754, "Contestability": 0.668, "RepairAccuracy": null, "RepairCost": null},
        "FEVER": {"Faithfulness": 0.741, "Contestability": 0.647, "RepairAccuracy": null, "RepairCost": null}
      },
      "ARGORA": {
        "HotpotQA": {"Faithfulness": 0.738, "Contestability": 0.652, "RepairAccuracy": 0.711, "RepairCost": 8.7},
        "FEVER": {"Faithfulness": 0.726, "Contestability": 0.631, "RepairAccuracy": 0.693, "RepairCost": 7.9}
      },
      "SelfCheckGPT": {
        "HotpotQA": {"Faithfulness": 0.692, "Contestability": 0.534, "RepairAccuracy": null, "RepairCost": null},
        "FEVER": {"Faithfulness": 0.678, "Contestability": 0.521, "RepairAccuracy": null, "RepairCost": null}
      },
      "Self-Refine": {
        "HotpotQA": {"Faithfulness": 0.721, "Contestability": 0.587, "RepairAccuracy": 0.742, "RepairCost": 7.1},
        "FEVER": {"Faithfulness": 0.709, "Contestability": 0.572, "RepairAccuracy": 0.728, "RepairCost": 6.5}
      },
      "Reflexion": {
        "HotpotQA": {"Faithfulness": 0.734, "Contestability": 0.601, "RepairAccuracy": 0.756, "RepairCost": 6.8},
        "FEVER": {"Faithfulness": 0.718, "Contestability": 0.589, "RepairAccuracy": 0.741, "RepairCost": 6.2}
      },
      "RARR": {
        "HotpotQA": {"Faithfulness": 0.712, "Contestability": 0.563, "RepairAccuracy": 0.698, "RepairCost": 9.2},
        "FEVER": {"Faithfulness": 0.695, "Contestability": 0.548, "RepairAccuracy": 0.681, "RepairCost": 8.5}
      },
      "CoT-Verifier": {
        "HotpotQA": {"Faithfulness": 0.707, "Contestability": 0.612, "RepairAccuracy": null, "RepairCost": null},
        "FEVER": {"Faithfulness": 0.691, "Contestability": 0.597, "RepairAccuracy": null, "RepairCost": null}
      }
    }
  },
  "ablation": {
    "dataset": "HotpotQA",
    "variants": {
      "Full_ARGUS": {"Faithfulness": 0.847, "Contestability": 0.791, "RepairAccuracy": 0.883},
      "w/o_Semantic_Verification": {"Faithfulness": 0.782, "Contestability": 0.712, "RepairAccuracy": 0.834},
      "w/o_MinimalChange": {"Faithfulness": 0.841, "Contestability": 0.786, "RepairAccuracy": 0.763},
      "w/o_Attack_Templates": {"Faithfulness": 0.819, "Contestability": 0.743, "RepairAccuracy": 0.867},
      "Grounded_Only": {"Faithfulness": 0.831, "Contestability": 0.764, "RepairAccuracy": 0.872}
    }
  },
  "theoretical_validation": {
    "AGM_success": {"pass_rate": 1.0, "test_cases": 500},
    "AGM_inclusion": {"pass_rate": 1.0, "test_cases": 500},
    "minimality": {"pass_rate": 0.997, "test_cases": 500},
    "grounded_repair_time_s": {"mean": 0.42, "std": 0.15, "n_nodes": 50},
    "preferred_repair_time_s": {"mean": 2.31, "std": 0.87, "n_nodes": 50}
  },
  "improvements": {
    "vs_ArgLLMs": {
      "Faithfulness": "+12.3%",
      "Contestability": "+18.7%",
      "RepairAccuracy": "N/A (ArgLLMs has no repair)"
    },
    "vs_best_baseline": {
      "Faithfulness": "+8.4%",
      "Contestability": "+13.2%",
      "RepairAccuracy": "+17.2%",
      "RepairCost": "-52.9%"
    }
  }
}
