% ===== ยง7  Conclusion =====
\section{Conclusion}\label{sec:conclusion}

We presented \textsc{Argus}, a framework that structures LLM self-explanations as argumentation frameworks, verifies them against formal semantics, and repairs them at minimum cost when new evidence arrives.
The minimal-change repair operator satisfies adapted AGM postulates---success, inclusion, and vacuity---and a representation theorem \emph{bidirectionally characterizes} the class of minimum-cost repair operators under positive costs.
The repair problem is tractable under grounded semantics, NP-complete under preferred/stable semantics, and $\Sigma_2^P$-complete under skeptical stable semantics; the $k$-neighborhood approximation maintains scalability.
Experiments on HotpotQA and FEVER yielded relative improvements of \improveFaithfulness{} in faithfulness and \improveContestability{} in contestability over the strongest argumentation baseline with the lowest repair cost.
Current limitations include dependence on LLM extraction quality and scalability to densely connected frameworks; future work targets open-ended generation with coherence-based acceptance, composition with sequence explanations~\citep{bengel2025sequence}, probabilistic repair under graded argument uncertainty~\citep{hunter2013probabilistic}, and integration into retrieval-augmented pipelines.

