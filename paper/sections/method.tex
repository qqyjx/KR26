% ===== ยง3  ARGUS Method =====
\section{The \textsc{Argus} Framework}\label{sec:method}

\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth,trim=10pt 40pt 10pt 25pt,clip]{figures/figure3.pdf}
\caption{The \textsc{Argus} pipeline. The repair stage (highlighted) is the core contribution; an evidence update~$\Delta$ triggers repair when the target argument is no longer accepted.}
\label{fig:pipeline}
\end{figure*}

We now present \textsc{Argus}, a four-stage pipeline (Figure~\ref{fig:pipeline}) that transforms an unverifiable LLM rationale into a formally grounded, repairable explanation.
Given a question~$q$, an answer~$a$, and a free-form rationale~$e$, the pipeline proceeds through structured extraction (\S\ref{sec:extraction}), relation discovery (\S\ref{sec:relation}), semantic verification (\S\ref{sec:verification}), and minimal-change repair (\S\ref{sec:repair}).
The first three stages serve as preprocessing; the repair stage constitutes the core contribution.

\subsection{Structured Extraction}\label{sec:extraction}

We prompt the LLM to decompose its rationale~$e$ into a set of argument units $\mathcal{A}=\{a_1,\dots,a_n\}$.
Each unit~$a_i$ is a structured record comprising a natural-language claim~$c_i$, a set of premise identifiers $P_i \subseteq \mathcal{A}\setminus\{a_i\}$ on which the claim depends, and a self-assessed confidence score $\gamma_i\in(0,1]$.
The prompt constrains the LLM to produce a JSON array of objects, each with fields \texttt{claim}, \texttt{premises}, and \texttt{confidence}, ensuring that every claim is atomic---that is, it asserts exactly one proposition that can be independently verified or rebutted.
We designate one distinguished unit~$a_t\in\mathcal{A}$ as the \emph{target argument}, whose claim directly supports the answer~$a$.

\subsection{Relation Discovery and Graph Construction}\label{sec:relation}

Given the argument units~$\mathcal{A}$, we construct an argumentation framework $\mathit{AF}=(\mathcal{A},\mathcal{R})$ as defined in Definition~\ref{def:af}.
For every ordered pair $(a_i,a_j)$ with $i\neq j$, we query a natural language inference (NLI) model---a neural classifier trained to determine entailment, contradiction, or neutrality between text pairs---to classify the relationship between~$c_i$ and~$c_j$.
A \emph{contradiction} verdict yields an attack $(a_i,a_j)\in\mathcal{R}$, while an \emph{entailment} verdict records a support link used for downstream analysis but not encoded in~$\mathcal{R}$, since Dung-style frameworks model attacks only~\cite{dung1995acceptability}.
To improve recall on domain-specific rebuttals, we maintain an \emph{attack template library}---a curated set of negation patterns, common exceptions, and defeasible-rule conflicts.
Each template generates a candidate counterargument that is tested against existing units via NLI before being admitted into~$\mathcal{R}$.

\subsection{Semantic Verification}\label{sec:verification}

With the framework $\mathit{AF}=(\mathcal{A},\mathcal{R})$ in hand, we compute its extensions under a chosen semantics~$\sigma$ such as grounded or preferred semantics.
The verification step checks whether the target argument~$a_t$ belongs to at least one $\sigma$-extension.
If $a_t$ is \emph{accepted}, the explanation is deemed internally consistent; if $a_t$ is \emph{rejected} or \emph{undecided}, the framework flags a verification failure.
In either case, the solver also returns a \emph{defense set}~$D\subseteq\mathcal{A}$---the minimal subset of arguments whose collective acceptability entails the status of~$a_t$---which serves as a compact certificate explaining the verdict to the user.

\subsection{Minimal-Change Repair}\label{sec:repair}

When new evidence contradicts the current explanation or the verification step detects a failure, \textsc{Argus} repairs the argumentation framework rather than regenerating the rationale from scratch.
The repair must satisfy two desiderata simultaneously: the target argument must attain a prescribed status under~$\sigma$, and the edit distance from the original framework must be minimized.
Definition~\ref{def:repair} formalizes this requirement.

\textbf{Repair Operations.}
Four elementary edit operations underlie the repair: $\mathsf{add\_arg}(a)$ and $\mathsf{del\_arg}(a)$ insert or remove an argument (deletions cascade to incident attacks), while $\mathsf{add\_att}(a_i,a_j)$ and $\mathsf{del\_att}(a_i,a_j)$ insert or remove attacks.
A set of operations yields a repaired framework $\mathit{AF}'=(\mathcal{A}',\mathcal{R}')$.

\textbf{Cost Function.}
Each operation~$o$ is assigned a strictly positive cost $\kappa(o)\in\mathbb{R}_{> 0}$.
We consider three cost models.
Under \emph{uniform cost}, every operation costs~$1$, so the objective reduces to minimizing the total number of edits.
Under \emph{confidence-weighted cost}, argument deletions are weighted by the confidence of the removed argument, $\kappa(\mathsf{del\_arg}(a_i))=\gamma_i$ (recall $\gamma_i > 0$ for all extracted arguments), while additions retain unit cost $\kappa(\mathsf{add\_arg})=\kappa(\mathsf{add\_att})=1$, reflecting the intuition that highly confident claims should be more expensive to retract.
Under \emph{structure-preserving cost}, deletions are penalized more heavily than additions, $\kappa(\mathsf{del\_\cdot})\;{=}\;w\cdot\kappa(\mathsf{add\_\cdot})$ for some $w>1$, encouraging the solver to repair by augmentation rather than removal.

The repair problem is formalized in Definition~\ref{def:repair}. Given the cost function~$\kappa$ and evidence update~$\Delta$, the solver seeks an optimal repair---a set of edit operations of minimum total cost such that $a_t$ attains the desired status under~$\sigma$.

\begin{example}[Continuing Example~\ref{ex:running}]\label{ex:cost}
Under confidence-weighted cost with $\gamma_5 = 0.90$ (a verified lab result) and $\gamma_3 = 0.75$ (a symptomatic inference), deleting~$a_5$ costs $\kappa(\mathsf{del\_arg}(a_5)) = 0.90$.
The augmentation repair $\{\mathsf{add\_arg}(a_6), \mathsf{add\_att}(a_6, a_5)\}$ avoids removing any high-confidence argument, yielding total cost $2\kappa(\mathsf{add\_\cdot})$; this repair is cheaper whenever $\kappa(\mathsf{add\_\cdot}) < 0.45$.
Under structure-preserving cost with $w=2$, deleting~$a_5$ costs~$2$ while the augmentation still costs~$2$, making the two equally expensive and allowing domain preferences to break the tie.
\end{example}

\textbf{ASP Encoding.}
We encode the repair problem as an answer set program following the methodology of Egly et al.~\cite{egly2010asparg} for argumentation reasoning and extending it with choice rules for repair operations.
The encoding consists of three components; at a high level, it mirrors an integer linear program where binary variables select edits, constraints enforce semantics, and the objective minimizes cost.
First, \emph{generate rules} introduce choice atoms for each candidate operation: the solver may optionally add or delete any argument or attack within the neighborhood subgraph.
Second, \emph{semantics constraints} enforce that the repaired framework satisfies~$\sigma$; for grounded semantics, these follow the characteristic-function fixed-point semantics of Egly~et~al.~\cite{egly2010asparg}.
Third, a \emph{weak constraint} minimizes the weighted sum of selected operations:
\[
  \mathsf{\#minimize}\bigl\{\kappa(o) : \mathsf{selected}(o)\bigr\}.
\]
Continuing with Example~\ref{ex:running}, the choice atoms include $\mathsf{add\_arg}(a_6)$ and $\mathsf{add\_att}(a_6, a_5)$, and the integrity constraints verify that $a_4$ belongs to the grounded extension of the repaired framework.
Algorithm~\ref{alg:repair} summarizes the complete procedure.
When the solver selects $\mathsf{add\_arg}(a)$, the natural-language claim for the new argument is generated by prompting the LLM to produce a rebuttal of the target's attacker, conditioned on the evidence update~$\Delta$; the resulting candidate is verified through the same NLI pipeline before admission.

\begin{algorithm}[tb]
\caption{\textsc{Argus} Repair}\label{alg:repair}
\begin{algorithmic}[1]
\REQUIRE $\mathit{AF}=(\mathcal{A},\mathcal{R})$, semantics $\sigma$, target $a_t$, desired status $s$, evidence $\Delta$, cost function $\kappa$, neighborhood bound $k$
\ENSURE Optimal repair $\mathit{Ops}^*$
\STATE $\mathcal{A}_{\Delta},\mathcal{R}_{\Delta} \leftarrow \textsc{Incorporate}(\mathit{AF}, \Delta)$
\STATE $\mathcal{N} \leftarrow k\text{-neighborhood of } a_t \text{ in } (\mathcal{A}\cup\mathcal{A}_{\Delta},\;\mathcal{R}\cup\mathcal{R}_{\Delta})$
\STATE $\Pi \leftarrow \textsc{EncodeASP}(\mathcal{N}, \sigma, a_t, s, \kappa)$
\STATE $M^* \leftarrow \textsc{Solve}(\Pi)$ \COMMENT{optimal answer set}
\STATE $\mathit{Ops}^* \leftarrow \{o \mid \mathsf{selected}(o) \in M^*\}$
\RETURN $\mathit{Ops}^*$
\end{algorithmic}
\end{algorithm}

\textbf{Approximation for Scalability.}
Even under preferred semantics the repair problem is NP-complete (Theorem~\ref{thm:complexity}), rising to $\Sigma_2^P$-completeness under skeptical stable semantics~\cite{dvorak2018computational}, so we introduce two approximation strategies.
First, a $k$-neighborhood restriction limits the search space to arguments within undirected distance~$k$ of the target in the attack graph.  The approximation is \emph{complete} for optimal repairs whose support set lies entirely within the $k$-neighborhood: if the unique optimal repair modifies only arguments at distance $\leq k$ from $a_t$, then the neighborhood-restricted problem has the same optimum.  A repair can be missed only when the optimal repair requires modifying an argument at distance $> k$---equivalently, when a long attack chain of length $> k$ is the sole route to defending $a_t$.  In our experiments, setting $k{=}3$ recovered optimal repairs in 99.7\% of cases while substantially reducing solver grounding, consistent with the shallow graph structure (median depth~3, maximum~7).
Second, when ASP solvers are unavailable, beam search over repair sequences with width~$b$ provides a bounded-depth heuristic alternative.
In principle, a repair valid for the subgraph may not preserve validity in the full framework if distant arguments influence the target's status; for deeper domains, $k$ should be increased accordingly.

\begin{table*}[t]
\caption{Main results on HotpotQA and FEVER.  Best in \textbf{bold}; runner-up \underline{underlined}. $\uparrow$ = higher is better, $\downarrow$ = lower is better. N/A = method lacks repair or coherence functionality. $^\dagger$Na\"{i}ve re-prompting baseline (destroys argumentation structure).}\label{tab:main}
\centering
\footnotesize
\setlength{\tabcolsep}{3.2pt}
\renewcommand{\arraystretch}{1.05}
\begin{tabular}{@{}l|cccccc|cccccc@{}}
\toprule
& \multicolumn{6}{c|}{\textbf{HotpotQA}} & \multicolumn{6}{c}{\textbf{FEVER}} \\
\textbf{Method} & Faith$\uparrow$ & Cont$\uparrow$ & RAcc$\uparrow$ & RCost$\downarrow$ & Coher$\uparrow$ & Time$\downarrow$ & Faith$\uparrow$ & Cont$\uparrow$ & RAcc$\uparrow$ & RCost$\downarrow$ & Coher$\uparrow$ & Time$\downarrow$ \\
\midrule
\multicolumn{13}{l}{\textit{Self-Correction Methods}} \\
SelfCheckGPT   & .693 & .524 & .701 & 8.4 & .68 & 2.8 & .674 & .498 & .685 & 7.9 & .66 & 2.5 \\
Self-Refine    & .712 & .541 & .736 & 7.1 & .72 & 4.5 & .698 & .519 & .721 & 6.8 & .70 & 4.2 \\
Reflexion      & .724 & .563 & .752 & 6.6 & .73 & 5.8 & .709 & .537 & .738 & 6.2 & .71 & 5.3 \\
RARR           & .738 & .547 & .769 & 5.8 & .71 & 3.2 & .721 & .531 & .754 & 5.5 & .69 & 2.9 \\
\midrule
\multicolumn{13}{l}{\textit{Verification-Oriented (incl.\ Retrieval-Augmented)}} \\
CoT-Verifier   & .751 & .589 & N/A  & N/A & N/A & 1.5 & .733 & .561 & N/A  & N/A & N/A & 1.3 \\
ArgLLMs        & .754 & .667 & N/A  & N/A & N/A & 2.1 & .741 & .649 & N/A  & N/A & N/A & 1.8 \\
FLARE          & .715 & .505 & .728 & 8.8 & .74 & 3.8 & .698 & .482 & .712 & 8.2 & .72 & 3.5 \\
FactScore      & .742 & .558 & N/A  & N/A & N/A & 2.5 & .728 & .535 & N/A  & N/A & N/A & 2.2 \\
\midrule
\multicolumn{13}{l}{\textit{Argumentation-Based}} \\
ARGORA         & \underline{.768} & \underline{.691} & \underline{.801} & \underline{5.1} & \underline{.75} & 1.8 & \underline{.752} & \underline{.672} & \underline{.788} & \underline{4.7} & \underline{.73} & 1.5 \\
Regenerate$^\dagger$ & .709 & ---  & .743 & --- & .65 & \textbf{0.5} & .695 & --- & .729 & --- & .63 & \textbf{0.4} \\
\midrule
\textsc{Argus} (Ours) & \textbf{\resultFaithHotpot} & \textbf{\resultContestHotpot} & \textbf{\resultRepairAccHotpot} & \textbf{\resultRepairCostHotpot} & \textbf{.82} & \underline{0.55} & \textbf{\resultFaithFEVER} & \textbf{\resultContestFEVER} & \textbf{\resultRepairAccFEVER} & \textbf{\resultRepairCostFEVER} & \textbf{.80} & \underline{0.47} \\
\bottomrule
\end{tabular}
\end{table*}

\begin{table*}[t]
\caption{Ablation study on HotpotQA and FEVER.  Each row removes one component from the full \textsc{Argus} pipeline. Best in \textbf{bold}.}\label{tab:ablation}
\centering
\footnotesize
\setlength{\tabcolsep}{3.2pt}
\renewcommand{\arraystretch}{1.05}
\begin{tabular}{@{}l|cccccc|cccccc@{}}
\toprule
& \multicolumn{6}{c|}{\textbf{HotpotQA}} & \multicolumn{6}{c}{\textbf{FEVER}} \\
\textbf{Variant} & Faith$\uparrow$ & Cont$\uparrow$ & RAcc$\uparrow$ & RCost$\downarrow$ & Coher$\uparrow$ & Time$\downarrow$ & Faith$\uparrow$ & Cont$\uparrow$ & RAcc$\uparrow$ & RCost$\downarrow$ & Coher$\uparrow$ & Time$\downarrow$ \\
\midrule
Full \textsc{Argus}       & \textbf{\resultFaithHotpot} & \textbf{\resultContestHotpot} & \textbf{\resultRepairAccHotpot} & \textbf{\resultRepairCostHotpot} & \textbf{.82} & .55 & \textbf{\resultFaithFEVER} & \textbf{\resultContestFEVER} & \textbf{\resultRepairAccFEVER} & \textbf{\resultRepairCostFEVER} & \textbf{.80} & .47 \\
w/o Semantic Verif. & .793 & .714 & .832 & 4.1 & .76 & .52 & .775 & .692 & .818 & 3.8 & .74 & .44 \\
w/o Minimal-Change  & .841 & .783 & .856 & 5.7 & .78 & .58 & .823 & .761 & .842 & 5.2 & .76 & .49 \\
w/o Attack Templ.   & .821 & .698 & .859 & 3.5 & .80 & .53 & .804 & .678 & .845 & 3.2 & .78 & .45 \\
Grounded Only       & .839 & .772 & .871 & \textbf{3.0} & .81 & \textbf{.15} & .822 & .752 & .858 & \textbf{2.6} & .79 & \textbf{.12} \\
\bottomrule
\end{tabular}
\end{table*}
